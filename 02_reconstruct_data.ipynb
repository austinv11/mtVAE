{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 19:54:47.694403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "2022-08-07 19:54:49.579449: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-07 19:54:49.580585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-07 19:54:49.595274: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-07 19:54:49.595304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8557ee92613c\n",
      "2022-08-07 19:54:49.595312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8557ee92613c\n",
      "2022-08-07 19:54:49.595432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.39.1\n",
      "2022-08-07 19:54:49.595453: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.39.1\n",
      "2022-08-07 19:54:49.595459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.39.1\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'), flush=True)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "#print(\"GPUs Available: \", tf.config.list_logical_devices('GPU'), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model and reconstruction paths\n",
    "model_path = 'models/'\n",
    "recon_path = 'results/reconstructions/'\n",
    "\n",
    "# VAE model paths\n",
    "path_vae     = model_path + 'VAE.h5'\n",
    "path_encoder = model_path + 'VAE_encoder.h5'\n",
    "path_decoder = model_path + 'VAE_decoder.h5'\n",
    "\n",
    "# Data paths\n",
    "USE_NA = False\n",
    "if USE_NA:\n",
    "    twins_path = \"data/BioBank_NA.xlsx\"\n",
    "else:\n",
    "    twins_path  = 'data/BioBank.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "twins_train_df = pd.read_excel(twins_path, sheet_name='Training Set', engine='openpyxl')\n",
    "twins_test_df  = pd.read_excel(twins_path, sheet_name='Testing Set', engine='openpyxl')\n",
    "twins_full_data = pd.concat([twins_train_df, twins_test_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 19:58:47.640642: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-07 19:58:47.652786: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-07 19:58:47.673729: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-08-07 19:58:47.676975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2749780000 Hz\n",
      "/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/sklearn/decomposition/_kernel_pca.py:261: LinAlgWarning: Ill-conditioned matrix (rcond=2.72317e-44): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n"
     ]
    }
   ],
   "source": [
    "# Data & model configuration\n",
    "input_dim = twins_train_df.shape[1]\n",
    "\n",
    "# Note, to reconstruct Figure 2a and 2b, which shows\n",
    "# the correlation matrix MSE curve for varying latent dimensionalities d,\n",
    "# run the following code in a loop with \n",
    "#latent_dims = [5, 10, 15, 18, 20, 30, 40, 60, 80, 100, 120, 160, 200]\n",
    "\n",
    "params = load_vae_parameters(optimal=False)\n",
    "\n",
    "intermediate_dim = max(params['encoder_units'], params['decoder_units'])\n",
    "latent_dim = 18\n",
    "\n",
    "kl_beta = params['kl_beta']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "batch_size = 256\n",
    "n_epochs = 1000\n",
    "# Instantiate model\n",
    "mtmodel = mtVAE(input_dim,\n",
    "                intermediate_dim,\n",
    "                latent_dim,\n",
    "                kl_beta,\n",
    "                learning_rate)\n",
    "\n",
    "\n",
    "# Load VAE model\n",
    "mtmodel.vae.load_weights(path_vae)\n",
    "mtmodel.encoder.load_weights(path_encoder)\n",
    "mtmodel.decoder.load_weights(path_decoder)\n",
    "\n",
    "\n",
    "if not USE_NA:\n",
    "    ######################\n",
    "    # Define PCA model\n",
    "    ######################\n",
    "    PCA_model_ = PCA_model(twins_train_df.values, latent_dim)\n",
    "\n",
    "    ######################\n",
    "    # Define KPCA models\n",
    "    ######################\n",
    "    poly_KPCA_model_ = KPCA_model(twins_train_df.values, latent_dim,\"poly\", 2, 0.001, 3, 5.0)\n",
    "    cosine_KPCA_model_ = KPCA_model(twins_train_df.values,latent_dim,\"cosine\", 1, 0, 0, 0)\n",
    "    sigmoid_KPCA_model_ = KPCA_model(twins_train_df.values,latent_dim,\"sigmoid\", 1, 0.05, 0, 0)\n",
    "    rbf_KPCA_model_ = KPCA_model(twins_train_df.values,latent_dim,\"rbf\", 1, 0.005, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create and save data reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create save paths for reconstructed data\n",
    "train_vae_recon = f'{recon_path}BB_train_VAE_reconstruction_d_{latent_dim}.csv'\n",
    "if not USE_NA:\n",
    "    train_pca_recon = f'{recon_path}BB_train_PCA_reconstruction_d_{latent_dim}.csv'\n",
    "    train_cosine_kpca_recon = f'{recon_path}BB_train_cosine_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    train_sigmoid_kpca_recon = f'{recon_path}BB_train_sigmoid_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    train_rbf_kpca_recon = f'{recon_path}BB_train_rbf_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    train_poly_kpca_recon = f'{recon_path}BB_train_poly_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "\n",
    "test_vae_recon = f'{recon_path}BB_test_VAE_reconstruction_d_{latent_dim}.csv'\n",
    "if not USE_NA:\n",
    "    test_pca_recon = f'{recon_path}BB_test_PCA_reconstruction_d_{latent_dim}.csv'\n",
    "    test_cosine_kpca_recon = f'{recon_path}BB_test_cosine_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    test_sigmoid_kpca_recon = f'{recon_path}BB_test_sigmoid_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    test_rbf_kpca_recon = f'{recon_path}BB_test_rbf_KPCA_reconstruction_d_{latent_dim}.csv'\n",
    "    test_poly_kpca_recon = f'{recon_path}BB_test_poly_KPCA_reconstruction_d_{latent_dim}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "vae_rcon = pd.DataFrame(mtmodel.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "vae_rcon.to_csv(train_vae_recon, index=False)\n",
    "del vae_rcon\n",
    "vae_rcon = pd.DataFrame(mtmodel.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "vae_rcon.to_csv(test_vae_recon, index=False)\n",
    "del vae_rcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pca_rcon = pd.DataFrame(PCA_model_.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "pca_rcon.to_csv(train_pca_recon, index=False)\n",
    "del pca_rcon\n",
    "pca_rcon = pd.DataFrame(PCA_model_.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "pca_rcon.to_csv(test_pca_recon, index=False)\n",
    "del pca_rcon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "kpca_rcon = pd.DataFrame(cosine_KPCA_model_.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "kpca_rcon.to_csv(train_cosine_kpca_recon, index=False)\n",
    "del kpca_rcon\n",
    "kpca_rcon = pd.DataFrame(cosine_KPCA_model_.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "kpca_rcon.to_csv(test_cosine_kpca_recon, index=False)\n",
    "del kpca_rcon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "kpca_rcon = pd.DataFrame(sigmoid_KPCA_model_.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "kpca_rcon.to_csv(train_sigmoid_kpca_recon, index=False)\n",
    "del kpca_rcon\n",
    "kpca_rcon = pd.DataFrame(sigmoid_KPCA_model_.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "kpca_rcon.to_csv(test_sigmoid_kpca_recon, index=False)\n",
    "del kpca_rcon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "kpca_rcon = pd.DataFrame(rbf_KPCA_model_.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "kpca_rcon.to_csv(train_rbf_kpca_recon, index=False)\n",
    "del kpca_rcon\n",
    "kpca_rcon = pd.DataFrame(rbf_KPCA_model_.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "kpca_rcon.to_csv(test_rbf_kpca_recon, index=False)\n",
    "del kpca_rcon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "kpca_rcon = pd.DataFrame(poly_KPCA_model_.reconstruct(twins_train_df.values),\n",
    "                            columns = twins_train_df.columns)\n",
    "kpca_rcon.to_csv(train_poly_kpca_recon, index=False)\n",
    "del kpca_rcon\n",
    "kpca_rcon = pd.DataFrame(poly_KPCA_model_.reconstruct(twins_test_df.values),\n",
    "                            columns = twins_test_df.columns)\n",
    "kpca_rcon.to_csv(test_poly_kpca_recon, index=False)\n",
    "del kpca_rcon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
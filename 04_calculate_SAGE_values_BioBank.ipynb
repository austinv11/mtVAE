{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 05:09:01.433879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-08-09 05:09:03.807983: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-09 05:09:03.809150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-09 05:09:03.823093: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-09 05:09:03.823131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8557ee92613c\n",
      "2022-08-09 05:09:03.823139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8557ee92613c\n",
      "2022-08-09 05:09:03.823277: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.39.1\n",
      "2022-08-09 05:09:03.823296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.39.1\n",
      "2022-08-09 05:09:03.823302: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.39.1\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sage\n",
    "\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'), flush=True)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "\n",
    "############################################\n",
    "# Define helper functions\n",
    "############################################\n",
    "\n",
    "def save_sages(sage_vals, path):\n",
    "    res = pd.DataFrame([data_cols, sage_vals.values, sage_vals.std]).T\n",
    "    res.columns = [\"metabolite_id\", \"sage_value\", \"sage_value_sd\"]\n",
    "    res.to_csv(path, index=False)\n",
    "    \n",
    "def save_pw_sages(sage_vals, pw_groupnames, path):\n",
    "    res = pd.DataFrame([pw_groupnames, sage_vals.values, sage_vals.std]).T\n",
    "    res.columns = [\"pathway_name\", \"sage_value\", \"sage_value_sd\"]\n",
    "    res.to_csv(path, index=False)\n",
    "\n",
    "def get_sage_pws(model, ref_data, test_data, dim, pw_groups, pw_groupnames, pw_type):\n",
    "\n",
    "    def get_dim_vals(dat):\n",
    "        return model.encode_mu(dat)[:,dim:(dim+1)]\n",
    "    \n",
    "    # calculate base values\n",
    "    dim_output = get_dim_vals(test_data)\n",
    "    \n",
    "    # Setup and calculate\n",
    "    # NOTE: any callable function that returns a prediction is allowed in PermutationSampler\n",
    "    imputer_pw = sage.GroupedMarginalImputer(ref_data[:10], pw_groups)\n",
    "    sampler_pw = sage.PermutationSampler(get_dim_vals, imputer_pw, 'mse')\n",
    "    sage_values_pw = sampler_pw(test_data, Y=dim_output, batch_size = 512)\n",
    "    \n",
    "    # rename dimension 0 to dimension 18\n",
    "    dim_idx = 18 if dim == 0 else dim\n",
    "    \n",
    "    if pw_type == \"super\": \n",
    "        save_pw_sages(sage_values_pw, pw_groupnames, f\"results/sage_values/VAE/superpw_dim_{dim_idx}.csv\")\n",
    "    elif pw_type == \"sub\":\n",
    "        save_pw_sages(sage_values_pw, pw_groupnames, f\"results/sage_values/VAE/subpw_dim_{dim_idx}.csv\")\n",
    "        \n",
    "    return sage_values_pw\n",
    "\n",
    "\n",
    "def get_sage_mets(model, ref_data, test_data, dim):\n",
    "\n",
    "    def get_dim_vals(dat):\n",
    "        return model.encode_mu(dat)[:,dim:(dim+1)]\n",
    "    \n",
    "    dim_output = get_dim_vals(test_data)\n",
    "    \n",
    "    # Setup and calculate\n",
    "    # NOTE: any callable function that returns a prediction is allowed in PermutationSampler\n",
    "    imputer = sage.MarginalImputer(ref_data[:10])\n",
    "    sampler = sage.PermutationSampler(get_dim_vals, imputer, 'mse')\n",
    "    sage_values = sampler(test_data, Y=dim_output, batch_size = 10)\n",
    "    \n",
    "    # rename dimension 0 to dimension 18\n",
    "    dim_idx = 18 if dim == 0 else dim\n",
    "    \n",
    "    save_sages(sage_values, f\"results/sage_values/VAE/met_dim_{dim_idx}.csv\")\n",
    "    \n",
    "    return sage_values\n",
    "\n",
    "\n",
    "def get_groups(pw_name):\n",
    "    # Feature groups\n",
    "    feature_groups = met_annos.groupby(pw_name)['COMP_IDstr'].apply(list).to_dict()\n",
    "\n",
    "    group_names = [group for group in feature_groups]\n",
    "    for col in feature_names:\n",
    "        if np.all([col not in group[1] for group in feature_groups.items()]):\n",
    "            group_names.append(col)\n",
    "\n",
    "    # Group indices\n",
    "    groups = []\n",
    "    for _, group in feature_groups.items():\n",
    "        ind_list = []\n",
    "        for feature in group:\n",
    "            ind_list.append(data_cols.index(feature))\n",
    "        groups.append(ind_list)\n",
    "        \n",
    "    return {'feature_groups':feature_groups, 'group_names':group_names, 'groups':groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Patients\n",
      "Read Data\n",
      "Load Model\n",
      "Load Weights\n",
      "Start SAGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 05:12:49.449587: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-09 05:12:49.457817: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-09 05:12:49.472988: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-08-09 05:12:49.475657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2749780000 Hz\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Initialize variables and instantiate objects\n",
    "############################################\n",
    "\n",
    "twins_path  = 'data/BioBank.xlsx'\n",
    "\n",
    "#aml_data = pd.read_excel(twins_path, sheet_name='Metabolite Annotations', engine=\"openpyxl\")\n",
    "#aml_anno = pd.read_excel(twins_path, sheet_name='Patient Information', engine=\"openpyxl\")\n",
    "print(\"Read Patients\")\n",
    "\n",
    "twins_train_df = pd.read_excel(twins_path, sheet_name='Training Set', engine=\"openpyxl\")\n",
    "twins_test_df  = pd.read_excel(twins_path, sheet_name='Testing Set', engine=\"openpyxl\")\n",
    "print(\"Read Data\")\n",
    "\n",
    "# these arrays are used for score calculations\n",
    "twins_train = twins_train_df.values\n",
    "twins_test  = twins_test_df.values\n",
    "\n",
    "model_path = 'models/'\n",
    "\n",
    "# Define paths for saved VAE model\n",
    "path_vae     = model_path + 'VAE.h5'\n",
    "path_encoder = model_path + 'VAE_encoder.h5'\n",
    "path_decoder = model_path + 'VAE_decoder.h5'\n",
    "\n",
    "# Data & model configuration\n",
    "input_dim = twins_train_df.shape[1]\n",
    "params = load_vae_parameters(optimal=False)\n",
    "\n",
    "intermediate_dim = max(params['encoder_units'], params['decoder_units'])\n",
    "latent_dim = 18\n",
    "\n",
    "kl_beta = params['kl_beta']\n",
    "learning_rate = params['learning_rate']\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 1000\n",
    "\n",
    "# instantiate model\n",
    "mtmodel = mtVAE(input_dim,\n",
    "                intermediate_dim,\n",
    "                latent_dim,\n",
    "                kl_beta,\n",
    "                learning_rate)\n",
    "\n",
    "print(\"Load Model\")\n",
    "\n",
    "# load model\n",
    "mtmodel.vae.load_weights(path_vae)\n",
    "mtmodel.encoder.load_weights(path_encoder)\n",
    "mtmodel.decoder.load_weights(path_decoder)\n",
    "\n",
    "print(\"Load Weights\")\n",
    "\n",
    "# Create groups to calculate grouped SAGE values\n",
    "#data_cols = aml_data.columns.to_list()\n",
    "met_annos = pd.read_excel(twins_path, sheet_name='Metabolite Annotations', engine=\"openpyxl\")\n",
    "data_cols = met_annos['COMP_IDstr'].to_list()\n",
    "#met_annos = met_annos.loc[met_annos['COMP_IDstr'].isin(data_cols)]\n",
    "feature_names = met_annos['COMP_IDstr'].to_list()\n",
    "biochemical_names = met_annos['BIOCHEMICAL'].to_list()\n",
    "print(\"Start SAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sage_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubpathway\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     14\u001B[0m     subpw          \u001B[38;5;241m=\u001B[39m get_groups(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUB_PATHWAY\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m     sage_pw_values \u001B[38;5;241m=\u001B[39m \u001B[43mget_sage_pws\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmtmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtwins_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtwins_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubpw\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgroups\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubpw\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgroup_names\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msub\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sage_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetabolite\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     18\u001B[0m     sage_met_values \u001B[38;5;241m=\u001B[39m get_sage_mets(mtmodel, twins_train, twins_test, latent_dim)\n",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36mget_sage_pws\u001B[0;34m(model, ref_data, test_data, dim, pw_groups, pw_groupnames, pw_type)\u001B[0m\n\u001B[1;32m     39\u001B[0m imputer_pw \u001B[38;5;241m=\u001B[39m sage\u001B[38;5;241m.\u001B[39mGroupedMarginalImputer(ref_data[:\u001B[38;5;241m10\u001B[39m], pw_groups)\n\u001B[1;32m     40\u001B[0m sampler_pw \u001B[38;5;241m=\u001B[39m sage\u001B[38;5;241m.\u001B[39mPermutationSampler(get_dim_vals, imputer_pw, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 41\u001B[0m sage_values_pw \u001B[38;5;241m=\u001B[39m \u001B[43msampler_pw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# rename dimension 0 to dimension 18\u001B[39;00m\n\u001B[1;32m     44\u001B[0m dim_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m18\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m dim\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/sage/permutation_sampler.py:119\u001B[0m, in \u001B[0;36mPermutationSampler.__call__\u001B[0;34m(self, X, Y, batch_size, detect_convergence, convergence_threshold, n_permutations, verbose, bar)\u001B[0m\n\u001B[1;32m    116\u001B[0m S[arange, inds] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# Make prediction with missing features.\u001B[39;00m\n\u001B[0;32m--> 119\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimputer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mS\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(y_hat\u001B[38;5;241m.\u001B[39mreshape(\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimputer\u001B[38;5;241m.\u001B[39msamples, \u001B[38;5;241m*\u001B[39my_hat\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    122\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(y_hat, y)\n",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36mget_sage_pws.<locals>.get_dim_vals\u001B[0;34m(dat)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_dim_vals\u001B[39m(dat):\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_mu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdat\u001B[49m\u001B[43m)\u001B[49m[:,dim:(dim\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n",
      "File \u001B[0;32m/home/mtVAE/models.py:251\u001B[0m, in \u001B[0;36mmtVAE.encode_mu\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode_mu\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:982\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    979\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_call_args(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    981\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_training_loop(x)\n\u001B[0;32m--> 982\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    984\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    985\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    986\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    987\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    988\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    990\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    991\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:706\u001B[0m, in \u001B[0;36mArrayLikeTrainingLoop.predict\u001B[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    703\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001B[1;32m    704\u001B[0m x, _, _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39m_standardize_user_data(\n\u001B[1;32m    705\u001B[0m     x, check_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, steps_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msteps\u001B[39m\u001B[38;5;124m'\u001B[39m, steps\u001B[38;5;241m=\u001B[39msteps)\n\u001B[0;32m--> 706\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpredict_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:384\u001B[0m, in \u001B[0;36mmodel_iteration\u001B[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001B[0m\n\u001B[1;32m    381\u001B[0m callbacks\u001B[38;5;241m.\u001B[39m_call_batch_hook(mode, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_index, batch_logs)\n\u001B[1;32m    383\u001B[0m \u001B[38;5;66;03m# Get outputs.\u001B[39;00m\n\u001B[0;32m--> 384\u001B[0m batch_outs \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mins_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch_outs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    386\u001B[0m   batch_outs \u001B[38;5;241m=\u001B[39m [batch_outs]\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:3922\u001B[0m, in \u001B[0;36mGraphExecutionFunction.__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   3919\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[1;32m   3920\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mflatten(inputs, expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 3922\u001B[0m   session \u001B[38;5;241m=\u001B[39m \u001B[43mget_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3923\u001B[0m   feed_arrays \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   3924\u001B[0m   array_vals \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:644\u001B[0m, in \u001B[0;36mget_session\u001B[0;34m(op_input_list)\u001B[0m\n\u001B[1;32m    642\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _MANUAL_VAR_INIT:\n\u001B[1;32m    643\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m session\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m--> 644\u001B[0m     \u001B[43m_initialize_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m session\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:1082\u001B[0m, in \u001B[0;36m_initialize_variables\u001B[0;34m(session)\u001B[0m\n\u001B[1;32m   1080\u001B[0m variables \u001B[38;5;241m=\u001B[39m _get_variables(get_graph())\n\u001B[1;32m   1081\u001B[0m candidate_vars \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1082\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m variables:\n\u001B[1;32m   1083\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(v, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_initialized\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m     candidate_vars\u001B[38;5;241m.\u001B[39mappend(v)\n",
      "File \u001B[0;32m/opt/conda/envs/mtvae_env/lib/python3.8/site-packages/tensorflow/python/util/object_identity.py:241\u001B[0m, in \u001B[0;36mObjectIdentityWeakSet.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    240\u001B[0m   keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_storage)\n\u001B[0;32m--> 241\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m keys:\n\u001B[1;32m    242\u001B[0m     unwrapped \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39munwrapped\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m unwrapped \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "############################################\n",
    "# MAIN PART OF SCRIPT\n",
    "############################################\n",
    "from pathlib import Path\n",
    "\n",
    "for latent_dim in range(18):\n",
    "    Path(f\"{latent_dim}.ignore\").touch()\n",
    "    for sage_type in ['superpathway', 'subpathway', 'metabolite']:\n",
    "        if sage_type == \"superpathway\":\n",
    "            superpw        = get_groups('SUPER_PATHWAY')\n",
    "            sage_pw_values = get_sage_pws(mtmodel, twins_train, twins_test, latent_dim, superpw['groups'], superpw['group_names'], \"super\")\n",
    "\n",
    "        elif sage_type == \"subpathway\":\n",
    "            subpw          = get_groups('SUB_PATHWAY')\n",
    "            sage_pw_values = get_sage_pws(mtmodel, twins_train, twins_test, latent_dim, subpw['groups'], subpw['group_names'], \"sub\")\n",
    "\n",
    "        elif sage_type == \"metabolite\":\n",
    "            sage_met_values = get_sage_mets(mtmodel, twins_train, twins_test, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
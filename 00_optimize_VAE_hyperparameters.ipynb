{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 04:24:28.787086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 04:24:30.338036: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-07 04:24:30.339088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-07 04:24:30.352313: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-07 04:24:30.352346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8557ee92613c\n",
      "2022-08-07 04:24:30.352354: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8557ee92613c\n",
      "2022-08-07 04:24:30.352451: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.39.1\n",
      "2022-08-07 04:24:30.352469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.39.1\n",
      "2022-08-07 04:24:30.352474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.39.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import kerastuner\n",
    "from kerastuner.tuners import Hyperband, BayesianOptimization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'), flush=True)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "#print(\"GPUs Available: \", tf.config.list_logical_devices('GPU'), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'data/BioBank.xlsx'\n",
    "\n",
    "bb_train_data = pd.read_excel(data_path, sheet_name='Training Set', engine='openpyxl')\n",
    "bb_test_data = pd.read_excel(data_path, sheet_name='Testing Set', engine='openpyxl')\n",
    "\n",
    "biobank_data = pd.concat([bb_train_data, bb_test_data], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data & model configuration\n",
    "batch_size = 256\n",
    "no_epochs = 1000\n",
    "latent_dim = 18\n",
    "\n",
    "original_dim = bb_train_data.shape[1]\n",
    "input_shape = (original_dim,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recommended to do this here: https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "        \n",
    "        \n",
    "def model_builder(hp):\n",
    "    # # =================\n",
    "    # # Encoder\n",
    "    # # =================\n",
    "\n",
    "    # Definition\n",
    "    i       = Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    x       = Dense(hp.Int('encoder_units',\n",
    "                           min_value=30,\n",
    "                           max_value=220,\n",
    "                           step=10))(i)\n",
    "    x       = LeakyReLU()(x)\n",
    "    \n",
    "    mu      = Dense(latent_dim, name='latent_mu')(x)\n",
    "    sigma   = Dense(latent_dim, name='latent_sigma')(x)\n",
    "\n",
    "    # Define sampling with reparameterization trick\n",
    "    def sample_z(args):\n",
    "        mu, sigma = args\n",
    "        batch     = K.shape(mu)[0]\n",
    "        dim       = K.int_shape(mu)[1]\n",
    "        eps       = K.random_normal(shape=(batch, dim))\n",
    "        return mu + K.exp(sigma / 2) * eps\n",
    "\n",
    "    # Use reparameterization trick to ....??\n",
    "    z       = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([mu, sigma])\n",
    "\n",
    "    # Instantiate encoder\n",
    "    encoder = Model(i, [mu, sigma, z], name='encoder')\n",
    "    \n",
    "    # =================\n",
    "    # Decoder\n",
    "    # =================\n",
    "\n",
    "    # Definition\n",
    "    d_i   = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "    \n",
    "    x     = Dense(hp.Int('decoder_units',\n",
    "                           min_value=20,\n",
    "                           max_value=220,\n",
    "                           step=10))(d_i)\n",
    "    x     = LeakyReLU()(x)\n",
    "        \n",
    "    o     = Dense(original_dim)(x)\n",
    "\n",
    "    # Instantiate decoder\n",
    "    decoder = Model(d_i, o, name='decoder')\n",
    "    \n",
    "    # =================\n",
    "    # VAE as a whole\n",
    "    # =================\n",
    "\n",
    "    # Define loss\n",
    "    def kl_reconstruction_loss(true, pred):\n",
    "      # Reconstruction loss\n",
    "        reconstruction_loss = mse(true, pred)\n",
    "        reconstruction_loss *= original_dim\n",
    "\n",
    "        # KL divergence loss\n",
    "        kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        \n",
    "        # weight KL divergence loss here\n",
    "        kl_loss *= hp.Float(\n",
    "        'kl_beta',\n",
    "        min_value=1e-3,\n",
    "        max_value=1e1,\n",
    "        sampling='LOG',\n",
    "        default=1e-2\n",
    "        )\n",
    "\n",
    "        return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    # Instantiate VAE\n",
    "    vae_outputs = decoder(encoder(i)[2])\n",
    "    vae         = Model(i, vae_outputs, name='vae')\n",
    "\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = Adam(hp.Float(\n",
    "        'learning_rate',\n",
    "        min_value=1e-4,\n",
    "        max_value=1e-2,\n",
    "        sampling='LOG',\n",
    "        default=1e-3\n",
    "    ), clipnorm=1.0)\n",
    "\n",
    "    # Compile VAE\n",
    "    vae.compile(optimizer=optimizer, loss=kl_reconstruction_loss, metrics = ['mse'], experimental_run_tf_function=False)\n",
    "    \n",
    "    return vae\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method HyperParameters._retrieve of <kerastuner.engine.hyperparameters.HyperParameters object at 0x7f667c8eec40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method HyperParameters._retrieve of <kerastuner.engine.hyperparameters.HyperParameters object at 0x7f667c8eec40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Set tuner parameters\n",
    "tuner = Hyperband(\n",
    "    model_builder,\n",
    "    objective='mse',\n",
    "    factor=2,\n",
    "    max_epochs=200,\n",
    "    directory='hyperband_optimization',\n",
    "    project_name='mtvae',\n",
    "    overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "encoder_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 30, 'max_value': 220, 'step': 10, 'sampling': None}\n",
      "decoder_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 220, 'step': 10, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "kl_beta (Float)\n",
      "{'default': 0.01, 'conditions': [], 'min_value': 0.001, 'max_value': 10.0, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 Complete [00h 00m 24s]\n",
      "mse: 4.7634968757629395\n",
      "\n",
      "Best mse So Far: 0.04789607971906662\n",
      "Total elapsed time: 00h 23m 58s\n",
      "\n",
      "Search: Running Trial #68\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "encoder_units     |130               |60                \n",
      "decoder_units     |140               |140               \n",
      "learning_rate     |0.0096456         |0.0023747         \n",
      "kl_beta           |6.0328            |0.023363          \n",
      "tuner/epochs      |2                 |2                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |7                 |7                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Train on 83893 samples, validate on 14805 samples\n",
      "Epoch 1/2\n",
      "   32/83893 [..............................] - ETA: 3:51 - loss: 304.9012 - mse: 1.2448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 04:52:14.803641: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34496/83893 [===========>..................] - ETA: 5s - loss: 82.9452 - mse: 0.3247"
     ]
    }
   ],
   "source": [
    "# Run Tuner\n",
    "# Runtime on MacBook Pro 2017: 01h 15m\n",
    "tuner.search(\n",
    "    bb_train_data, bb_train_data,\n",
    "    validation_data = (bb_test_data, bb_test_data),\n",
    "    callbacks = []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Print out best tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tuner.results_summary(num_trials = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(best_hps.get('encoder_units'))\n",
    "print(best_hps.get('decoder_units'))\n",
    "print(best_hps.get('learning_rate'))\n",
    "print(best_hps.get('kl_beta'))\n",
    "\n",
    "with open(\"optimal_parameters.csv\", 'w') as f:\n",
    "    f.write(\"param,value,integer\\n\")\n",
    "    f.write(\"encoder_units,\")\n",
    "    f.write(str(best_hps.get('encoder_units')))\n",
    "    f.write(\",1\\n\")\n",
    "    f.write(\"decoder_units,\")\n",
    "    f.write(str(best_hps.get('decoder_units')))\n",
    "    f.write(\",1\\n\")\n",
    "    f.write(\"learning_rate,\")\n",
    "    f.write(str(best_hps.get('learning_rate')))\n",
    "    f.write(\",0\\n\")\n",
    "    f.write(\"kl_beta,\")\n",
    "    f.write(str(best_hps.get('kl_beta')))\n",
    "    f.write(\",0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}